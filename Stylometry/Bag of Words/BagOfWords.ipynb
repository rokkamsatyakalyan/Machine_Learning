{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authorship Attribution\n",
    "\n",
    "In this project, we train our model with writings of different authors and try to predict the correct author. In this version, we are going to predict the results using bag of words technique and Naive Bayes prediction algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data Preprocessing:\n",
    "\n",
    "We received the writing assignments from the softskills department. This data has many null values(missing assignments) and repeated values(Student Details and Question related Information). We dropped all the unwanted data and missing student assignmets.  This data is used to generate a csv file which has all student information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "\n",
    "First, we should load the data and print any five data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_label</th>\n",
       "      <th>author_writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>99</td>\n",
       "      <td>Exercise 1Make the following sentences more co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>99</td>\n",
       "      <td>Exercise 1Make the following sentences more co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>99</td>\n",
       "      <td>Q. Make the sentences more concise:1. We certa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>99</td>\n",
       "      <td>Listening and Note taking: As I understood to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>99</td>\n",
       "      <td>Sir/Madam I am venkatWhen i was trolled your w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author_label                                     author_writing\n",
       "1023            99  Exercise 1Make the following sentences more co...\n",
       "1024            99  Exercise 1Make the following sentences more co...\n",
       "1025            99  Q. Make the sentences more concise:1. We certa...\n",
       "1026            99  Listening and Note taking: As I understood to ...\n",
       "1027            99  Sir/Madam I am venkatWhen i was trolled your w..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('scan1.csv',sep=',', header=None, names=['author_label','ass_num', 'author_writing'])\n",
    "\n",
    "\n",
    "# df = pd.read_csv('bow3.csv',sep=',', header=None, names=['author_label', 'author_writing'])\n",
    "# Output printing out last 5 columns\n",
    "\n",
    "df = df.drop('ass_num', axis=1)\n",
    "df.tail()\n",
    "\n",
    "# print len(df['author_writing'][0].split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of data points. Our dataset contains 1028 tuples. and two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1028, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into Train and Test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We should train the model before testing. But we need a training set and a testing set. So, we should divide the data into test and train sets by using train_test_split module from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 1028\n",
      "Number of rows in the training set: 771\n",
      "Number of rows in the test set: 257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['author_writing'],df['author_label'],random_state=1)\n",
    "\n",
    "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Bag of Words\n",
    "\n",
    "To apply the Naive Bayes theorem to our dataset, we should convert all our data into numeric values since sklearn can't work with non numeric values. So, we created a frequency matrix(word frequency) of our dataset and apply Bayes theorem to that. So, we used a module called CountVectorizer to that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should apply bayes technique for this dataset. So, we should import MultinomialNB module from sklearn. Here, we use Multinimial Naive Bayes because it good for classification with discrete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now that we trained our model, it's time to test the model with the dataset.\n",
    "\n",
    "predictions = naive_bayes.predict(testing_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance our model can be known by computing the accuracy, precision, recall and the f1 score of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy score: ', '0.0155642023346')\n",
      "('Precision score: ', '0.0583657587549')\n",
      "('Recall score: ', '0.0155642023346')\n",
      "('F1 score: ', '0.0230127848805')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions,average=\"weighted\")))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions,average=\"weighted\")))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions,average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "Since we got very less scores, we can't just conclude that our model is wrong. The other factors can also affect. Here we found out some factors which affected the scores.\n",
    "\n",
    "1. The data is not sufficient enough to train the model.\n",
    "2. Data contains a lot of noise. Quality of data is not good.\n",
    "3. The questions are not open ended. So the students are forced to write on the topic which they are given, which is not helpful in classifying a writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
